# build requirements
[build-system]
requires = ["setuptools < 70.0.0", "torch >= 2.3.0, < 2.4"]
build-backend = "setuptools.build_meta"

# Pytest
[tool.pytest.ini_options]
# By default, skip gpu tests
addopts = "--tb=short -m 'not gpu'"

markers = [
    # For distributed testing
    "world_size(val)",
    # Should be run during daily regression
    "daily",
    # Whether the test will be reading data from a remote source, and may require credentials
    "remote",
    # whether the test requires a gpu
    "gpu",
]

filterwarnings = [
    # "error",  # warnings should be treated like errors, but still need to fix some warnings
    'ignore:ExtraArgumentWarning',  # extra arguments originate from pytest-specific CLI args
    'ignore:DistributedDefaultValueWarning',  # default distributed values are fine
    'ignore:NoDistributedWarning',  # running without distributed is fine
    'ignore:Deterministic mode is activated:UserWarning',  # all tests run with deterministic mode
    'ignore:SubsetNumBatchesWarning',  # different subsets OK for testing
    'ignore:No optimizer:UserWarning',  # testing defaults
    'ignore:No scheduler:UserWarning',  # testing defaults
    'ignore::DeprecationWarning:tensorboard',  # ignore tensorboard
]

# Enable logging for pytest
log_cli = true
log_cli_level = "INFO"
log_cli_format = "%(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)"
log_cli_date_format = "%Y-%m-%d %H:%M:%S"

# Coverage
[tool.coverage.run]
parallel = true
branch = true
relative_files = true
concurrency = ["thread"]
include = [
    "megablocks/*"
]
